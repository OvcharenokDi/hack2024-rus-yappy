{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e14ce4-2736-4ee2-b0e6-2c8bf34bd110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /home/user1/environments/hack/lib/python3.10/site-packages (from matplotlib) (10.4.0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/user1/environments/hack/lib/python3.10/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/user1/environments/hack/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a1671e-9374-4211-b0fa-32c6c6cc52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import imagehash\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torchvision import models, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e8d4b-ecfe-4ff6-a817-88023a369e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "def neural_hash(img):\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    return output.numpy().flatten()\n",
    "\n",
    "\n",
    "def crop_resistant_hash(img, hash_func=imagehash.whash, hash_size=8, mode='haar', multires=True, grid_size=3, overlap=0.5):\n",
    "    if multires:\n",
    "        hashes = []\n",
    "        width, height = img.size\n",
    "        grid_width = math.ceil(width / grid_size)\n",
    "        grid_height = math.ceil(height / grid_size)\n",
    "\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                left = int(j * grid_width * (1 - overlap))\n",
    "                upper = int(i * grid_height * (1 - overlap))\n",
    "                right = min(left + grid_width, width)\n",
    "                lower = min(upper + grid_height, height)\n",
    "                cropped_img = img.crop((left, upper, right, lower))\n",
    "                h = hash_func(cropped_img, mode=mode, hash_size=hash_size)\n",
    "                hashes.append(h.hash.flatten())\n",
    "\n",
    "        combined_hash = np.concatenate(hashes)\n",
    "        return combined_hash\n",
    "    else:\n",
    "        return hash_func(img, hash_size=hash_size).hash.flatten()\n",
    "\n",
    "\n",
    "def calculate_hashes_and_features(image_path):\n",
    "    try:\n",
    "        # Открытие изображения и конвертация в RGB\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Вычисление хешей\n",
    "        phash = imagehash.phash(img, hash_size=8, highfreq_factor=4)\n",
    "        whash = imagehash.whash(img, hash_size=8, mode='db2')\n",
    "        #whash = imagehash.whash(img, image_scale=64, hash_size=32, mode='haar')\n",
    "        colorhash = imagehash.colorhash(img, binbits=8)\n",
    "        cr_hash = crop_resistant_hash(img, hash_func=imagehash.whash, hash_size=8, mode='db2', multires=True)\n",
    "\n",
    "        # Добавление цветовой гистограммы\n",
    "        color_hist = cv2.calcHist([img_cv], [0, 1, 2], None, [8, 8, 8],\n",
    "                                  [0, 256, 0, 256, 0, 256])\n",
    "        color_hist = cv2.normalize(color_hist, color_hist).flatten()\n",
    "\n",
    "        # print(f\"HOG {image_path}\")\n",
    "        #\n",
    "        # # # Добавление признаков HOG\n",
    "        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        # hog_features, hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "        #                               cells_per_block=(2, 2), block_norm='L2-Hys',\n",
    "        #                               visualize=True, feature_vector=True)\n",
    "\n",
    "        # Добавление Local Binary Patterns (LBP)\n",
    "        lbp = local_binary_pattern(gray, P=24, R=3, method='uniform')\n",
    "        (lbp_hist, _) = np.histogram(lbp.ravel(),\n",
    "                                     bins=np.arange(0, 24 + 3),\n",
    "                                     range=(0, 24 + 2))\n",
    "        lbp_hist = lbp_hist.astype(\"float\")\n",
    "        lbp_hist /= (lbp_hist.sum() + 1e-7)\n",
    "\n",
    "        # Добавление ключевых точек и дескрипторов (ORB)\n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "        if descriptors is not None:\n",
    "            # Усреднение дескрипторов или использование другого подхода\n",
    "            orb_features = descriptors.mean(axis=0)\n",
    "        else:\n",
    "            orb_features = np.zeros(orb.descriptorSize())\n",
    "\n",
    "        neural = neural_hash(img)\n",
    "\n",
    "        # Преобразование хешей в плоские массивы\n",
    "        features = [\n",
    "            # cr_hash,\n",
    "            whash.hash.flatten(),\n",
    "            phash.hash.flatten(),\n",
    "            # colorhash.hash.flatten(),\n",
    "            # color_hist.flatten(),\n",
    "            # lbp_hist.flatten(),\n",
    "            # orb_features.flatten()\n",
    "            # neural\n",
    "        ]\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    hashes = calculate_hashes_and_features(image_path)\n",
    "    return np.concatenate(hashes)\n",
    "\n",
    "\n",
    "def load_faiss_index(index_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    return index\n",
    "\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    dataset = np.load(dataset_path)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def search_similar_images(query_image_path, index, dataset, paths, top_k=5):\n",
    "    # Обработка запроса\n",
    "    query_vector = process_image(query_image_path)\n",
    "    query_vector = np.expand_dims(query_vector, axis=0).astype('float32')\n",
    "\n",
    "    with open('minmax_scaler.pkl', 'rb') as file:\n",
    "        scaler = pickle.load(file)\n",
    "\n",
    "        if query_vector.shape[1] != scaler.n_features_in_:\n",
    "            raise ValueError(f\"Ожидалось {scaler.n_features_in_} признаков, получено {query_vector.shape[1]}.\")\n",
    "\n",
    "        query_vector = scaler.transform(query_vector)\n",
    "\n",
    "        # Поиск в индексе\n",
    "        distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "        # Получение путей к похожим изображениям (предполагается, что у вас есть список путей)\n",
    "        similar_images = []\n",
    "        for idx in indices[0]:\n",
    "            similar_image_path = paths[idx]\n",
    "            # Здесь предполагается, что dataset содержит пути к изображениям\n",
    "            similar_images.append(similar_image_path)\n",
    "\n",
    "        return similar_images, distances[0]\n",
    "\n",
    "\n",
    "def search_similar_images_by_uuid(query_image):\n",
    "    uuid = query_image.split('/')[-1].split('_')[0]\n",
    "\n",
    "    # Выполнение поиска\n",
    "    similar_images, distances = search_similar_images(query_image, index, dataset, paths, top_k=500)\n",
    "\n",
    "    top_5_results = []\n",
    "\n",
    "    # Вывод результатов\n",
    "    print(f\"Похожие изображения для {query_image}:\")\n",
    "    count = 0\n",
    "    for img, dist in zip(similar_images, distances):\n",
    "        if not img.startswith(f\"./dataset_new2/{uuid}\"):\n",
    "            print(f\"Путь: {img}, Расстояние: {dist}\")\n",
    "            top_5_results.append({\"img\": img, \"dist\": dist})\n",
    "            if count == 5:\n",
    "                return top_5_results\n",
    "            count += 1\n",
    "\n",
    "\n",
    "def frame_difference(frame1, frame2, threshold=25):\n",
    "    # Преобразование кадров в grayscale для упрощения обработки\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Вычисление абсолютной разницы между кадрами\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "    # Применение порогового значения\n",
    "    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Вычисление процентного соотношения измененных пикселей\n",
    "    non_zero_count = cv2.countNonZero(thresh)\n",
    "    total_pixels = thresh.size\n",
    "    percentage = (non_zero_count / total_pixels) * 100\n",
    "\n",
    "    return percentage\n",
    "\n",
    "\n",
    "def extract_frames(video_path, output_dir):\n",
    "    # Получаем имя видео без расширения\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    # Открываем видеофайл\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Не удалось открыть видеофайл {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # print(f\"Кадровая частота (FPS): {fps}\")\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while ret:\n",
    "        ret, current_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Получение текущего номера кадра\n",
    "        frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "        # Вычисление времени в секундах\n",
    "        time_seconds = frame_number / fps\n",
    "\n",
    "        if saved_count == 0:\n",
    "            # Создаем имя файла для кадра\n",
    "            frame_filename = f\"{video_name}_{time_seconds}.jpg\"\n",
    "            frame_path = os.path.join(output_dir, frame_filename)\n",
    "\n",
    "            # Сохраняем кадр\n",
    "            cv2.imwrite(frame_path, current_frame)\n",
    "            saved_count += 1\n",
    "        else:\n",
    "            difference = frame_difference(prev_frame, current_frame)\n",
    "            if difference >= 7:\n",
    "                # Создаем имя файла для кадра\n",
    "                frame_filename = f\"{video_name}_{time_seconds}.jpg\"\n",
    "                frame_path = os.path.join(output_dir, frame_filename)\n",
    "\n",
    "                # Сохраняем кадр\n",
    "                cv2.imwrite(frame_path, current_frame)\n",
    "                saved_count += 1\n",
    "                # print(f\"Сохранен кадр {frame_count} с разницей {difference:.2f}%\")\n",
    "\n",
    "        prev_frame = current_frame\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Извлечено {saved_count} кадров из {video_path} с разницей 7% и более.\")\n",
    "\n",
    "\n",
    "def get_frame_histogram(frame):\n",
    "    \"\"\"\n",
    "    Вычисляет гистограмму цвета для кадра.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Используем гистограмму для каналов H и S\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [50, 60], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "\n",
    "def are_histograms_similar(hist1, hist2, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Сравнивает две гистограммы с использованием коэффициента корреляции.\n",
    "    \"\"\"\n",
    "    correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return correlation > threshold\n",
    "\n",
    "\n",
    "def extract_diverse_frames(video_path, max_frames=30):\n",
    "    \"\"\"\n",
    "    Извлекает максимальное количество (не более max_frames) наиболее разнообразных кадров из видео.\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка: Не удалось открыть видео.\")\n",
    "        return []\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    selected_frames = []\n",
    "    histograms = []\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = frame_count / fps\n",
    "    interval = max(1, int(frame_count / (max_frames * 2)))  # Интервалы для выбора кадров\n",
    "\n",
    "    current_frame = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Получение текущего номера кадра\n",
    "        frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "        # Вычисление времени в секундах\n",
    "        time_seconds = frame_number / fps\n",
    "\n",
    "        if current_frame % interval == 0:\n",
    "            hist = get_frame_histogram(frame)\n",
    "\n",
    "            # Проверяем, похож ли текущий кадр на уже выбранные\n",
    "            similar = False\n",
    "            for existing_hist in histograms:\n",
    "                if are_histograms_similar(hist, existing_hist):\n",
    "                    similar = True\n",
    "                    break\n",
    "\n",
    "            if not similar:\n",
    "                selected_frames.append({\"video_name\": video_name, \"frame\": frame, \"time_seconds\": time_seconds})\n",
    "                histograms.append(hist)\n",
    "                if len(selected_frames) >= max_frames:\n",
    "                    break\n",
    "\n",
    "        current_frame += 1\n",
    "\n",
    "    cap.release()\n",
    "    return selected_frames\n",
    "\n",
    "\n",
    "def select_unique_frames(video_path, max_frames=30, hash_size=8, frame_interval=10):\n",
    "    \"\"\"\n",
    "    Извлекает уникальные кадры из видео.\n",
    "\n",
    "    :param video_path: Путь к видеофайлу.\n",
    "    :param max_frames: Максимальное количество уникальных кадров.\n",
    "    :param hash_size: Размер хэша для сравнения (чем больше, тем точнее).\n",
    "    :param frame_interval: Интервал между кадрами для выборки.\n",
    "    :return: Список уникальных кадров в формате OpenCV.\n",
    "    \"\"\"\n",
    "    # Получаем имя видео без расширения\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка открытия видео файла.\")\n",
    "        return []\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    unique_frames = []\n",
    "    hashes = set()\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened() and len(unique_frames) < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Получение текущего номера кадра\n",
    "        frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "        # Вычисление времени в секундах\n",
    "        time_seconds = frame_number / fps\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Преобразуем кадр из BGR (OpenCV) в RGB (PIL)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(frame_rgb)\n",
    "\n",
    "            # Вычисляем хэш кадра\n",
    "            frame_hash = imagehash.average_hash(pil_image, hash_size=hash_size)\n",
    "\n",
    "            if frame_hash not in hashes:\n",
    "                hashes.add(frame_hash)\n",
    "                unique_frames.append({\"video_name\": video_name, \"frame\": frame, \"time_seconds\": time_seconds})\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return unique_frames\n",
    "\n",
    "\n",
    "def remove_dir(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Директория '{path}' и все её содержимое успешно удалены.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при удалении директории: {e}\")\n",
    "\n",
    "\n",
    "def extract_frames(video_path, max_frames=100, step=30):\n",
    "    \"\"\"\n",
    "    Извлекает кадры из видео с заданным шагом.\n",
    "\n",
    "    :param video_path: Путь к видеофайлу.\n",
    "    :param max_frames: Максимальное количество извлечённых кадров.\n",
    "    :param step: Шаг извлечения кадров (количество пропускаемых кадров).\n",
    "    :return: Список извлечённых кадров.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened() and len(frames) < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % step == 0:\n",
    "            # Конвертируем цветовое пространство из BGR в RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def compute_features(frames):\n",
    "    \"\"\"\n",
    "    Вычисляет вектор признаков для каждого кадра.\n",
    "\n",
    "    :param frames: Список кадров.\n",
    "    :return: Массив признаков.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for frame in frames:\n",
    "        # Простой пример: усреднённые цветовые значения\n",
    "        feature = frame.mean(axis=(0, 1))\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def select_representative_frames(frames, features, num_frames=5):\n",
    "    \"\"\"\n",
    "    Выбирает наиболее репрезентативные кадры на основе средней близости.\n",
    "\n",
    "    :param frames: Список кадров.\n",
    "    :param features: Массив признаков.\n",
    "    :param num_frames: Количество кадров для выбора.\n",
    "    :return: Список выбранных кадров.\n",
    "    \"\"\"\n",
    "    similarity_matrix = cosine_similarity(features)\n",
    "    # Вычисляем среднее сходство каждого кадра с другими\n",
    "    mean_similarities = similarity_matrix.mean(axis=1)\n",
    "    # Получаем индексы кадров с наивысшей средней сходностью\n",
    "    selected_indices = np.argsort(mean_similarities)[-num_frames:]\n",
    "    # Сортируем выбранные индексы по порядку появления в видео\n",
    "    selected_indices = sorted(selected_indices)\n",
    "    return [frames[i] for i in selected_indices]\n",
    "\n",
    "\n",
    "# def save_frames(frames, output_folder):\n",
    "#     \"\"\"\n",
    "#     Сохраняет список кадров в указанную папку.\n",
    "#\n",
    "#     :param frames: Список кадров в виде массивов NumPy\n",
    "#     :param output_folder: Путь к папке для сохранения изображений\n",
    "#     \"\"\"\n",
    "#     import os\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "#\n",
    "#     for idx, frame in enumerate(frames):\n",
    "#         frame_filename = f\"{frame['video_name']}_{frame['time_seconds']}.jpg\"\n",
    "#         frame_path = os.path.join(output_folder, frame_filename)\n",
    "#         cv2.imwrite(frame_path, frame['frame'])\n",
    "\n",
    "def save_frames(frames, output_folder):\n",
    "    for idx, frame in enumerate(frames):\n",
    "        filename = f\"file_{idx + 1}.jpg\"\n",
    "        frame_path = os.path.join(output_folder, filename)\n",
    "        plt.imsave(frame_path, frame)\n",
    "\n",
    "\n",
    "def top_5_videos(video_path):\n",
    "    temp_dir = f'./temp/{uuid.uuid4()}'\n",
    "    os.mkdir(temp_dir)\n",
    "\n",
    "    frames = extract_frames(video_path, max_frames=60, step=30)\n",
    "    print(f\"Извлечено {len(frames)} кадров из видео.\")\n",
    "\n",
    "    features = compute_features(frames)\n",
    "    selected_frames = select_representative_frames(frames, features, num_frames=5)\n",
    "\n",
    "    #unique_frames = extract_diverse_frames(video_path)\n",
    "    #save_frames(unique_frames, temp_dir)\n",
    "    save_frames(selected_frames, temp_dir)\n",
    "\n",
    "    # extract_frames(video_path=video_path, output_dir=temp_dir)\n",
    "    image_paths = glob.glob(os.path.join(temp_dir, '**', '*.jpg'), recursive=True)\n",
    "\n",
    "    sample_size = max(1, int(len(image_paths) * 1))\n",
    "    sampled_image_paths = random.sample(image_paths, sample_size) if len(image_paths) >= sample_size else image_paths\n",
    "\n",
    "    uuid_distances = {}\n",
    "\n",
    "    for query_image in sampled_image_paths:\n",
    "        top_5_video = search_similar_images_by_uuid(query_image)\n",
    "        # Извлекаем img_uuid из пути изображения\n",
    "        img_uuid = top_5_video[0]['img'].split('/')[-1].split('_')[0]\n",
    "        current_dist = top_5_video[0]['dist']\n",
    "\n",
    "        # Если img_uuid еще не в словаре, добавляем его с текущим расстоянием\n",
    "        if img_uuid not in uuid_distances:\n",
    "            uuid_distances[img_uuid] = current_dist\n",
    "        else:\n",
    "            # Сравниваем и сохраняем минимальное расстояние\n",
    "            if current_dist < uuid_distances[img_uuid]:\n",
    "                uuid_distances[img_uuid] = current_dist\n",
    "\n",
    "    # Сортируем словарь по значению расстояния в порядке возрастания\n",
    "    sorted_uuid_distances = sorted(uuid_distances.items(), key=lambda item: item[1])\n",
    "\n",
    "    # Получаем первый элемент из отсортированного списка\n",
    "    first_uuid, first_distance = sorted_uuid_distances[0]\n",
    "\n",
    "    print(f\"UUID с наименьшим расстоянием: {first_uuid}, Расстояние: {first_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80963a6a-4380-4653-a294-fdfe55195968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлечено 52 кадров из видео.\n",
      "Похожие изображения для ../temp/1e34f83e-63d1-47e3-bf59-08c6242dc395/file_4.jpg:\n",
      "Путь: ./dataset_new2/2da574f2-5ae7-4d85-9f5b-c2970a315c1c_0.43333333333333335.jpg, Расстояние: 3838.589111328125\n",
      "Путь: ./dataset_new2/2bbac52a-7a2b-40df-87e0-99198d3fa147_5.433333333333334.jpg, Расстояние: 4143.13232421875\n",
      "Путь: ./dataset_new2/2da574f2-5ae7-4d85-9f5b-c2970a315c1c_0.6333333333333333.jpg, Расстояние: 4164.88134765625\n",
      "Путь: ./dataset_new2/3f0c4cc9-f977-4d16-a02b-500eb6e49a69_5.933333333333334.jpg, Расстояние: 4165.380859375\n",
      "Путь: ./dataset_new2/275f26e4-8e54-4536-abd7-3c0aaad845d6_4.033333333333333.jpg, Расстояние: 4184.3701171875\n",
      "Путь: ./dataset_new2/03ab1552-7ea5-4ec4-abd7-cf60e543de16_18.033333333333335.jpg, Расстояние: 4219.85595703125\n",
      "Похожие изображения для ../temp/1e34f83e-63d1-47e3-bf59-08c6242dc395/file_5.jpg:\n",
      "Путь: ./dataset_new2/03ab1552-7ea5-4ec4-abd7-cf60e543de16_18.033333333333335.jpg, Расстояние: 4408.41943359375\n",
      "Путь: ./dataset_new2/182901f0-3e62-4d1d-a2e1-22e092db7992_1.7.jpg, Расстояние: 4462.7490234375\n",
      "Путь: ./dataset_new2/1d954b4f-3d7c-48c4-bf89-8726686c67f8_0.03333333333333333.jpg, Расстояние: 4484.87109375\n",
      "Путь: ./dataset_new2/51b7b4dc-5e27-4d06-82ae-574bb5134421_16.033333333333335.jpg, Расстояние: 4528.70947265625\n",
      "Путь: ./dataset_new2/1b877bfa-0872-4a8e-aedb-c02afc33980b_4.838171504838171.jpg, Расстояние: 4550.1845703125\n",
      "Путь: ./dataset_new2/03d6286b-d464-445f-b1fa-2bf322db0676_8.2.jpg, Расстояние: 4562.5478515625\n",
      "Похожие изображения для ../temp/1e34f83e-63d1-47e3-bf59-08c6242dc395/file_1.jpg:\n",
      "Путь: ./dataset_new2/03ab1552-7ea5-4ec4-abd7-cf60e543de16_18.033333333333335.jpg, Расстояние: 3613.442626953125\n",
      "Путь: ./dataset_new2/1b877bfa-0872-4a8e-aedb-c02afc33980b_4.838171504838171.jpg, Расстояние: 3642.11572265625\n",
      "Путь: ./dataset_new2/51b7b4dc-5e27-4d06-82ae-574bb5134421_16.033333333333335.jpg, Расстояние: 3880.46484375\n",
      "Путь: ./dataset_new2/54594ec8-e1c2-43c3-88cb-51917ebf1055_36.7.jpg, Расстояние: 3913.53955078125\n",
      "Путь: ./dataset_new2/3739da22-e526-43b7-a5d5-673b905f0908_0.03333333333333333.jpg, Расстояние: 3937.85595703125\n",
      "Путь: ./dataset_new2/4c8910ea-777a-4c53-90e6-c6aed49b7eb9_4.64.jpg, Расстояние: 3941.446044921875\n",
      "Похожие изображения для ../temp/1e34f83e-63d1-47e3-bf59-08c6242dc395/file_2.jpg:\n",
      "Путь: ./dataset_new2/833ce0a1-6d08-422c-8a34-9fab9eb4f004_5.033333333333333.jpg, Расстояние: 3619.519287109375\n",
      "Путь: ./dataset_new2/4c8910ea-777a-4c53-90e6-c6aed49b7eb9_16.6.jpg, Расстояние: 3621.652099609375\n",
      "Путь: ./dataset_new2/2da574f2-5ae7-4d85-9f5b-c2970a315c1c_10.633333333333333.jpg, Расстояние: 3666.861328125\n",
      "Путь: ./dataset_new2/54594ec8-e1c2-43c3-88cb-51917ebf1055_36.7.jpg, Расстояние: 3682.30517578125\n",
      "Путь: ./dataset_new2/3945c0f5-4ad7-4b6c-be3f-e2f79566be96_3.7666666666666666.jpg, Расстояние: 3702.84423828125\n",
      "Путь: ./dataset_new2/4c8910ea-777a-4c53-90e6-c6aed49b7eb9_39.6.jpg, Расстояние: 3804.98828125\n",
      "Похожие изображения для ../temp/1e34f83e-63d1-47e3-bf59-08c6242dc395/file_3.jpg:\n",
      "Путь: ./dataset_new2/54594ec8-e1c2-43c3-88cb-51917ebf1055_36.7.jpg, Расстояние: 3566.983642578125\n",
      "Путь: ./dataset_new2/1b877bfa-0872-4a8e-aedb-c02afc33980b_4.838171504838171.jpg, Расстояние: 3770.046142578125\n",
      "Путь: ./dataset_new2/03ab1552-7ea5-4ec4-abd7-cf60e543de16_18.033333333333335.jpg, Расстояние: 3794.325927734375\n",
      "Путь: ./dataset_new2/03d6286b-d464-445f-b1fa-2bf322db0676_8.2.jpg, Расстояние: 3886.433837890625\n",
      "Путь: ./dataset_new2/4c8910ea-777a-4c53-90e6-c6aed49b7eb9_4.64.jpg, Расстояние: 3902.506591796875\n",
      "Путь: ./dataset_new2/4904f2e0-0876-4f25-bba3-97806456bd31_0.03333333333333333.jpg, Расстояние: 3933.593994140625\n",
      "UUID с наименьшим расстоянием: 54594ec8-e1c2-43c3-88cb-51917ebf1055, Расстояние: 3566.983642578125\n"
     ]
    }
   ],
   "source": [
    "# Пути к индексам и данным\n",
    "index_path = '../faiss/image_index.faiss'\n",
    "dataset_path = '../faiss/image_dataset.npy'\n",
    "path_path = '../faiss/path_dataset.npy'\n",
    "\n",
    "# Загрузка индекса и набора данных\n",
    "index = load_faiss_index(index_path)\n",
    "dataset = load_dataset(dataset_path)\n",
    "paths = load_dataset(path_path)\n",
    "\n",
    "top_5_videos('../train_data_yappy/train_dataset/4904f2e0-0876-4f25-bba3-97806456bd31.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954583fa-06b5-40ce-9177-b0c240dba70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
